---
title: 📖 데이터 중심 애플리케이션 설계
author: Rosie Yang
date: 2024-05-06
category: study
layout: post
---

> '데이터 중심 애플리케이션 설계' 온오프라인 스터디 내용과 기타 참고자료를 정리한 내용입니다. 

## Contents 

<table>
    <tr>
        <td style="width:30%;">
            <img src="/assets/gitbook/post_images/database/DDIA.jpg">
        </td>
        <td>
            <ul>
                <li><a href="/study/2024/05/06/Designing_data_intensive_applications.html#intro">Intro</a></li>
                <li>Part1. 데이터 시스템의 기초</li>
                <li><a href="/study/2024/05/06/Designing_data_intensive_applications.html#01-신뢰할-수-있고-확장-가능하며-유지보수하기-쉬운-애플리케이션">1장. 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션</a></li>
		<li><a href="/study/2024/05/06/Designing_data_intensive_applications.html#02-데이터-모델과-질의-언어">2장. 데이터 모델과 질의 언어</a></li>
            </ul>
        </td>
    </tr>
</table>

<br>

## Intro
엄청난 양의 트래픽, 개발주기 단축, 자유 오픈소스 소프트웨어, 병렬처리의 증가, 서비스형 인프라(IaaS), 고가용성 요구 등으로 기술은 발전했습니다.
이러한 기술의 발전과 더불어 단순히 계산 중심적인 애플리케이션이 아닌 데이터의 양, 복잡성, 데이터의 변화 속도 등을 고려하는 데이터 중심적 애플리케이션이 가능해졌습니다.
+ 하둡(Hadoop): 대규모 데이터 처리를 위한 오픈 소스 프레임워크로, 분산 저장과 처리를 지원합니다.
+ 스파크(Spark): 대규모 데이터 처리 및 분석을 위한 클러스터 컴퓨팅 프레임워크로, 빠른 속도의 데이터 처리를 제공합니다.
+ NoSQL: 관계형 데이터베이스 모델을 따르지 않는 다양한 형태의 데이터 저장소로, 확장성과 유연성이 강조됩니다.
+ 빅데이터: 기존 데이터베이스 도구로 처리하기 어려운 대규모 데이터 세트로, 다양한 유형과 소스에서 생성될 수 있습니다.
+ 샤딩(Sharding): 데이터를 여러 서버에 분산 저장하여 데이터베이스의 성능을 향상시키는 기술로, 데이터를 조각내어 저장합니다.
+ 최종적 일관성(Eventual Consistency): 분산 시스템에서 일정 시간이 지난 후에는 모든 복제본이 동일한 상태가 되는 일관성 모델입니다.
+ ACID: 트랜잭션의 속성을 나타내는 네 가지 속성인 원자성(Atomicity), 일관성(Consistency), 고립성(Isolation), 지속성(Durability)을 의미합니다.
+ CAP 정리(CAP Theorem): 분산 시스템에서 일관성(Consistency), 가용성(Availability), 분할 내성(Partition Tolerance) 중에서 두 가지만 보장할 수 있다는 이론입니다.
+ 맵리듀스(MapReduce): 대규모 데이터 세트를 병렬 처리하기 위한 프로그래밍 모델로, 분산 컴퓨팅 환경에서 사용됩니다.

이번 스터디에서 개인적으로 데이터 중심 애플리케이션과 실제로 대형 웹사이트와 서비스들이 어떻게 돌아가는지에 대한 부분을 중점적으로 이해하고 넘어가는 것을 목표로 하고 있습니다. 

<br>

## 01. 신뢰할 수 있고 확장 가능하며 유지보수하기 쉬운 애플리케이션
데이터 중심 애플리케이션은 데이터를 보관하는 **데이터베이스**, 한 번 불러온 데이터를 기억해서 다시 읽기 없이 수행결과를 가지고 오는 **캐시**, 사용자가 키워드로 검색하거나 필터링을 가능하게 하는 **검색 색인**, 
비동기 처리를 위해 다른 프로세스로 메시지를 보내는 **스트림 처리**, 주기적으로 다량의 데이터를 분석하는 **일괄 처리(batch processing)**를 필요로 합니다. 

요즘은 메시지 큐로 사용하는 데이터 스토어인 레디스, 데이터베이스처럼 지속성을 보장하는 아파치 카프카와 같이 그 경계가 흐려지고 있기 때문에 **데이터 시스템**이라는 포괄적 용어를 사용합니다.
또한 애플리케이션의 task가 많아짐에 따라 여러 도구를 사용하게 됩니다. 애플리케이션 관리 캐시 계층과 full-text 검색 서버의 캐시나 색인을 유지하는 것은 모두 애플리케이션 코드로 연결되어 있습니다.
즉, 개발자는 이제 애플리케이션 개발자뿐만 아니라 데이터 시스템 설계자이기도 합니다.
+ 엘라스틱서치(Elasticsearch): 분산형 검색 및 분석 엔진으로, 대용량의 데이터를 신속하게 검색하고 분석하는 데 사용됩니다. 오픈 소스이며, 실시간 데이터 검색과 분석을 지원합니다.
+ 솔라(Solr): 엘라스틱서치와 유사한 오픈 소스 검색 플랫폼으로, Apache Lucene 기반으로 만들어졌습니다. 대용량의 데이터를 색인하고 검색하는 데 사용되며, 고성능의 검색 기능을 제공합니다.

### 신뢰성(Reliability)
하드웨어나 소프트웨어의 결함, 심지어 인적 오류와 같은 역경에도 시스템은 지속적으로 올바르게 동작해야 합니다. 즉, 결함이 있어도 정상적으로 동작해야 한다는 것인데 여기서 결함은 장애와 동일하지 않습니다. 
장애는 사용자에게 필요한 서비스를 제공하지 못하고 시스템 전체가 멈추게 되는 경우를 말합니다. 결함으로 인한 장애가 발생하지 않도록 내결함성 구조를 설계하는 것이 좋은데 넷플릭스 카오스 몽키가 이런 접근 방식의 한 예입니다.
+ [넷플릭스 카오스 몽키(Chaos Monkey)](https://netflix.github.io/chaosmonkey/How-to-deploy/)
  + 카오스 멍키는 어떤 장애가 발생할지 모르는 상황을 위해 서비스를 공급하는 인스턴스를 무작위로 셧다운시켜버리는 것으로 지금은 운영 이슈 테스트를 위한 개발 원칙으로 자리잡았습니다. 넷플릭스는 자사의 내결함성 전략을 '실패를 피하는 가장 좋은 방법은 지속적으로 실패하는 것'으로 삼고 카오스 엔지니어링을 수행한다고 합니다.
  + [스프링부트 카오스 멍키 라이브러리](https://codecentric.github.io/chaos-monkey-spring-boot/latest/)

<p style="text-align: center; margin: 50px 0">
  <img src="/assets/gitbook/post_images/database/chaos_monkey.png">
</p> 

**하드웨어 오류**  
하드디스크의 평균 장애 시간은 약 10~50년으로 보고됐으며, 10,000개의 디스크로 구성된 저장 클러스터는 평균적으로 하루에 한 개의 디스크가 죽는다고 예상해야 합니다.
시스템 장애율을 줄이기 위해서는 중복을 추가해 구성할 수 있었으며 일부 고가용성이 필요한 소수의 애플리케이션에 한해 다중 장비 중복으로 만들었습니다. 
+ 중복을 추가한다는 것은 디스크 RAID 구성, 서버의 이중 전원 디바이스, 핫 스왑이 가능한 CPU, 데이터센터의 건전지와 예비 전원용 디젤 발전기와 같은 것을 의미합니다.
최근에는 클라우드 플랫폼과 같이 다중 장비를 구성하는 것이 쉬워졌지만 각 장비 인스턴스의 신뢰성보다 유연성과 탄력성을 우선적으로 할 경우에 적합한 방식입니다. 
+ 어느 정도 규모가 있는 시스템에서는 단일 서버 시스템보다는 순회식 업그레이드가 가능하도록 장비 장애를 견딜 수 있는 설계가 필요합니다.

**소프트웨어 오류**  
다수의 하드웨어 구성요소에 장애가 발생하지 않는 경우도 있고, 시스템 내 체계적 오류로 일부 프로세스의 공유 자원을 과도하게 사용하므로 다른 구성요소의 장애가 발생하는 경우도 있습니다.
이런 경우는 예상도 어렵기 때문에 테스트, 프로세스 격리, 모니터링 등으로 지속적으로 확인할 필요가 있습니다.
+ 리눅스 커널의 버그로 많은 애플리케이션이 일제히 멈춰버린 원인이 된 2012년 6월 30일 윤초

**인적 오류**  
운영자의 설정 오류 등과 같은 것으로 다음과 같은 방식으로 신뢰성을 높일 수 있습니다. (버그는 생산성 저하의 원인이 되고, 사이트 중단은 매출 손실과 명성에 타격을 주기 때문)
+ 인터페이스, API와 같은 추상화
+ 실수로 인한 장애가 발생할 가능성이 있는 부분을 분리해 실제 사용자에게 비 프로덕션 샌드박스 제공
+ 단위테스트와 통합테스트
  + 정상적인 동작에서 발생하지 않는 코너 케이스를 다루는데 용이
+ 데이터 재계산 도구를 제공
+ 성능지표와 명확한 모니터링 대책 마련

### 확장성(Scalability)
시스템의 데이터 양, 트래픽 양, 복잡도가 증가하면서 이를 처리할 수 있는 적절한 방법이 있어야 합니다. 
규모가 커짐에 따라 부하가 증가되기 때문인데, 단순히 확장가능한지 여부보다는 특정 방식으로 시스템이 커졌을 때 대처방안, 추가 부하를 다루기 위한 계산 자원의 투입 등과 같은 질문을 할 필요가 있습니다.
부하는 **부하 매개변수**로 나타낼 수 있는데 예를 들면, 웹 서버의 초당 요청 수, 데이터베이스의 읽기 대 쓰기 비율, 대화방의 동시 활성 사용자, 캐시 적중률 등이 있습니다.

##### 트위터 사례
트위터의 홈 타임라인을 생각해봅시다. 한 유저가 트윗을 작성했을 때, 이 유저의 팔로워들은 홈 타임라인에서 유저가 작성한 새로운 트윗을 볼 수 있어야 합니다.  
1. 각 팔로워들이 홈 타임라인을 여는 시점에 자기가 팔로우 하는 사람들의 트윗을 찾고 시간순으로 나열해서 보여주는 방식을 택할 수 있을 것 입니다.
2. 캐시를 이용하는 방법도 있습니다. 빠르게 홈 타임라인을 보여주는 것이 중요하고 그 데이터를 반복해서 질의해 올 필요가 없다면, 홈 타임라인의 내용을 캐시에 두고 반복적인 요청을 기억해 두었다가 처리할 수 있습니다.
   + 실제로 트위터에서 트윗 게시 요청량이 홈 타임라인 읽기 요청량에 비해 훨씬 적기 때문에, 트윗을 작성하면 그 유저를 팔로우하는 사람들의 각각의 홈 타임라인 캐시에 최신 트윗을 삽입하는 방식으로 쓰기 시점에 더 많은 일을 하도록 했습니다.

하지만 인플루언스와 같이 팔로우가 많은 사람이 트윗을 쓴다면 어떨까요?  
트윗 작성시점에 쓰기 요청이 많아지고 적시에 트윗을 전송해야한다는 목표를 달성하기 어려울 수 있습니다. 따라서 트위터는 최종적으로 대부분 2의 방법대로 트윗의 읽기 작업을 캐시화하되, 
특정 사용자에 한하여 팬 아웃에서 제외하고 유명인의 트윗을 팔로우 하는 경우는 다시 1번의 방법처럼 읽는 시점에 홈 타임라인에 합쳐서 제공하는 방식을 택했습니다.

##### 지연시간과 응답시간
응답시간은 클라이언트 과전에서 본 시간으로 요청을 처리하는데 실제 시간 외에도 네트워크 지연과 큐 지연도 포함된 개념입니다. 반면, 지연시간은 요청이 처리되길 기다리는 시간으로 서비스를 기다리며 휴지 상태인 시간을 말합니다.  
응답시간을 측정 가능한 값의 분포로 평균 값으로 생각하지만 일반적으로는 백분위를 사용하는 것이 좋습니다. 사용자가 얼마나 오랫동안 기다려야하는지 알려면 중앙값을, 특이 값이 얼마나 좋지 않은지 알아보려면 상위 백분위를 살펴보는 것도 좋습니다.
상위 백분위는 꼬리 지연 시간(tail latency)이라고도 하며, 95분위 응답시간이 1.5초라고 하면 1.5초 미만인 요청이 100개 중에 95개인 것을 말합니다.
+ 응답시간은 대체로 요청마다 다양한 값을 얻게 되는데 백그라운드 프로세스의 컨텍스트 스위치, 네트워크 패킷 손실과 TCP 재전송, 가비지 컬렌션 휴지, 디스크에서 읽기를 강제하는 페이지 폴트, 서버 렉의 기계적인 진동 등이 원인이 될 수 있기 때문입니다.
+ 서비스 수준 목표(SLO), 서비스 수준 협약서(SLA)
+ 선두 차단(head-of-line blocking): 서버에서 후속 요청이 빠르게 처리되더라도 이전 요청이 완료되길 기다리는 시간 때문에 전체적인 응답시간이 느리다고 생각할 수 있습니다.
+ 꼬리 지연 증폭: 여러 번의 백엔드 호출로 느린 호출이 되고 응답시간이 느려지게 되는 효과

##### 부하 대응 접근 방식
아키텍처를 결정하는 요소는 읽기의 양, 쓰기의 양, 저장할 데이터의 양, 데이터의 복잡도, 응답 시간 요구사항, 접근 패턴 등이 있습니다.
+ 용량 확장(scaling up) >> 수직 확장(vertical scaling)
+ 규모 확장(scaling out) >> 수평 확장(horizontal scaling)
+ 탄력적인 시스템은 부하를 예측할 수 없을 만큼 높은 경우에 유용하지만 수동적으로 확장하는 시스템이 더 간단하고 운영상 예상치 못한 일이 더 적습니다.
+ 스타트업 초기 단계나 검증되지 않은 제품의 경우에 미래를 갖어한 부하에 대비해 확장하기보다는 빠르게 반복해서 제품 기능을 개선하는 작업이 좀 더 중요합니다.

### 유지보수성(Maintainability)
모든 사용자가 시스템 상에서 생산적으로 작업할 수 있게 해야 합니다. 
+ 운영성: 운영팀이 시스템을 원활하게 운영할 수 있게 쉽게 만드는 것
+ 단순성: 복잡도를 최대한 제거해 새로운 엔지니어가 이해하기 쉽게 만드는 것
  + 우발적 복잡도를 제거하기 위해 추상화를 이용해서 세부 구현 사항을 숨길 수 있습니다.
+ 발전성: 엔지니어가 이후에 쉽게 면경할 수 있게 하는 것

<br>

## 02장. 데이터 모델과 질의 언어


### 관계형 모델과 문서 모델

데이터 모델은 데이터의 관계, 흐름에 필요한 처리 과정에 대한 추상화된 모형입니다. 데이터 모델을 통해 이 프로그램이 어떻게 작성되었는지 문제에 대한 접근방법에 대해 알 수 있습니다. 이렇게 데이터 모델을 사용하므로써 계층 간의 복잡성을 숨길 수 있습니다. 즉, 추상화를 통해 데이터를 재사용한다거나 단순화하여 애플리케이션, 데이터베이스, 하드웨어 개발자들이 효율적으로 일할 수 있게 합니다.

**관계형 데이터베이스와 NoSQL**
관계형 데이터베이스는 관계(relation)을 바탕으로 튜플과 로우를 가지는 데이터베이스입니다. 객체, XML, 네트워크 모델들에도 불구하고 관계형 모델이 여전히 비즈니스 데이터 처리에 우위를 가지고 있습니다. NoSQL은 Not Only SQL로 재해석되어 쓰기 처리량이 높은 경우에 관계형 데이터베이스를 보완할 수 있는 이점을 가지고 있습니다. 현재는 애플리케이션에 따라 관계형 데이터베이스와 NoSQL을 함께 사용해서 다중 저장소 지속성을 지닌 데이터베이스 설계 방식으로 구축하는 방식이 많이 적용되고 있습니다.  

객체에 의해 모델 사이의 임피던스 불일치가 발생하는데, 애플리케이션 코드와 질의에 의한 데이터베이스 저장시의 문제를 말합니다. ORM의 지원에도 한계가 있고, 관계형 데이터베이스에서 복잡한 참조 처리로 불필요한 테이블이 다량 생성되기도 합니다. 이 경우, 하나의 결과를 가지고 오기 위해 많은 조인 처리로 성능 또한 저하될 수 있습니다.   

**문서 지향 데이터베이스**
문서 지향 데이터베이스(몽고, 리싱크, 카우치 등)에서는 JSON, XML을 지원해서 스키마보다 더 나은 지역성을 갖을 수 있습니다. 스키마가 없다는 것은 문서에 포함된 필드의 존재를 보장하지 않는 것을 의미합니다. 일반적으로 문서 지향 데이터베이스는 조인에 대한 지원이 부족합니다. 상위 레코드 내에 중첩된 레코드를 저장하는 방식입니다. 관계형의 외래 키와 달리 문서형 모델에서는 문서 참조(document reference)를 사용합니다.

### 데이터를 위한 질의 언어

SQL은 선언형 질의어인 반면 IMS와 코다실은 명령형 코드를 이용한 질의입니다. 명령형 질의는 특정 순서로 특정 연산을 수행하게 지시하고, 선언형 질의는 종종 병렬 실행에 적합하며 데이터베이스에만 국한되는 것이 아니라 다른 환경에서도 사용될 수 있습니다.  

맵듀리스 질의는 대량의 데이터를 처리하기 위한 모델로 일부 NoSQL에서 지원하고 있습니다. 주로 많은 문서를 대상으로 read-only 질의 수행시 사용됩니다. 저수준의 프로그래밍 모델로 주로 분산 시스템에서 사용되며 맵(map) 단계에서는 입력 데이터를 키-값 쌍으로 변환하고 병렬로 동시 처리하며 중간 결과를 생성합니다. 리듀스(reduce) 단계에서는 맵 단계의 중간 결과를 키를 기반으로 그룹화하고 집계합니다. 리듀스 함수를 사용해서 중간 결과를 집계하고 최종 결과를 생성합니다.

### 그래프형 데이터 모델

그래프형 데이터 모델은 다대다 관계가 일반적인 모델에서 정점과 간선이라는 객체로 이뤄진 데이터 모델을 말합니다. 이는 동종 데이터에 국한되지 않습니다.  

**속성 그래프 모델**  
속성 그래프 모델은 고유한 식별자 / 유출 간선 집합 / 유입 간선 집합 / 속성 컬렉션의 정점으로 가지며, 정점은 다른 정점과 간선으로 연결됩니다. 일련의 정점을 따라 앞뒤 방향으로 순회하기에 많은 유연성을 제공합니다. 구조가 다른 경우나 데이터 입도가 다양한 경우도 가능합니다.

**사이퍼 질의 언어**  
속성 그래프를 위한 선언형 질의 언어로 Neo4j 그래프 데이터베이스용으로 제작되었습니다. 정점은 id로 지정하고, 간선을 `(꼬리노드 id) -[:간선 label]=>(머리노드 id)`의 형태로 생성합니다. 선언형 언어이기 때문에 질의 최적화기가 가장 효율적인 전략을 자동적으로 선택합니다.

**트리플 저장소와 스파클**
트리플 저장소는 속성 그래프 모델과 거의 유사하며, 모든 정보를 (주어, 서술서, 목적어)와 같은 구문의 형식으로 나누어 저장합니다. 여기서 트리플의 주어는 그래프의 정점과 동등하며 목적어는 문자열이나 숫자 같은 원시 데이터 타입이거나 그래프의 다른 정점 중 하나를 의미합니다.  
```
_:lucy a :Person; :name "Lucy"; :bornIn _:idaho._
```

스파클 질의 언어는 RDF(Resource Description Framework) 데이터 모델을 사용한 트리플 저장소 질의 언어입니다. 사이퍼보다 먼저 만들어졌고 사이퍼 패턴 매칭으로 유사한 형태를 띕니다. 

**데이터 로그**  
스파클이나 사이퍼보다 더 오래된 언어로 서술어로 작성하며 select로 바로 질의하는 것이 아니라 단계를 나눠서 조금씩 질의하는 방식입니다.
```
// 데이터 정의
name(namerica, 'North America').
type(namerica, continent).

// rule 정의
within_recursive(Location, name) :- name(Location, name).
within_recursive(Location, name) :- within(Location, Via),
									within_recursive(Via, Name).

migrated(Name, BorIn, LivingIn) :- name(Person, Name),
									born_in(Person, BornLoc),
									...
									within_recursive(LivingLoc, LivingIn).
```

**다른 데이터 모델과의 차이**  
그래프 데이터 모델은 네트워크 데이터 모델과 달리, vertex는 edge로 다른 vertex와 자유롭게 연결되고 고유 id를 사용해 빠르게 탐색이 가능하다는 장점이 있습니다. 정렬 시점 또한 다른데 그래프 모델은 읽기 질의시 유연하게 정렬됩니다. 또한 문서 데이터베이스와 달리 그래프 데이터베이스는 모든 것이 잠재적으로 관련이 있다는 사용 사례를 대상으로 합니다.
<div style="padding:3px; margin:200px 0;"></div>   
